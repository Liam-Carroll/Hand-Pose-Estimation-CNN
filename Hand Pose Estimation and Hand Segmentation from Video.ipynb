{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea63cb00-3623-4677-9c94-447f62aa2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "import os\n",
    "import keyboard\n",
    "import cv2\n",
    "# import mediapipe as mp\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import colorsys\n",
    "import math\n",
    "#import uuid\n",
    "#import os    \n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from queue import Queue\n",
    "\n",
    "confidenceThreshold = 0.89\n",
    "\n",
    "#custom width control\n",
    "custom_width_g = 15\n",
    "#Recommend running FTST on its own\n",
    "simoultFTST = False;\n",
    "#Sampling period(in num frames)\n",
    "qMaxSize = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3c4c6c-d26d-47de-be57-1c5885c18c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.getcwd()+'/model/modelA_batch32_epochstr15_n128.h5') #Loading model from dir\n",
    "poses = np.array(['call_me',\n",
    "                  'fingers_crossed',\n",
    "                  'okay',\n",
    "                  'paper',\n",
    "                  'peace',\n",
    "                  'rock',\n",
    "                  'rock_on',\n",
    "                  'scissor',\n",
    "                  'thumbs',\n",
    "                  'up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ab964a-a5f5-4435-832e-302015a1590f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rgb2hsv(rgb):\n",
    "    colorInFloat = colorsys.rgb_to_hsv(rgb[0]/float(255), rgb[1]/float(255), rgb[2]/float(255))\n",
    "    colorOut = (int(colorInFloat[0]*255), int(colorInFloat[1]*255), int(colorInFloat[2]*255))\n",
    "    return colorOut\n",
    "\n",
    "def boundTo255(numPassed, depth):\n",
    "    return max(0, min(numPassed+depth, 255))\n",
    "\n",
    "def customSkinTones(averageColorRGB, hueThresh, satThresh, valThresh):\n",
    "    ## Returns Upper and Lower skin tones based on thresh and average skin color passed from face detection\n",
    "    # Convert Color to HSV\n",
    "    averageColorHSV = rgb2hsv(averageColorRGB)\n",
    "    \n",
    "    # Define range of acceptable skin tones\n",
    "    \n",
    "    #Default range\n",
    "    # hueThresh = 10 \n",
    "    # satThresh = 60\n",
    "    # valThresh = 85\n",
    "    \n",
    "    ## Lower tone\n",
    "    #Hue\n",
    "    lowerHue = boundTo255(averageColorHSV[0],-1*hueThresh)\n",
    "    #Sat\n",
    "    lowerSat = boundTo255(averageColorHSV[1],-1*satThresh)\n",
    "    #Val\n",
    "    lowerVal = boundTo255(averageColorHSV[2],-1*valThresh)\n",
    "    \n",
    "    ## Upper Tone\n",
    "    #Hue\n",
    "    upHue = boundTo255(averageColorHSV[0],hueThresh)\n",
    "    #Sat\n",
    "    upSat = boundTo255(averageColorHSV[1],satThresh)\n",
    "    #Val\n",
    "    upVal = boundTo255(averageColorHSV[2],valThresh)\n",
    "    \n",
    "    # print('Lower:',lowerHue,lowerSat,lowerVal,'      Upper:',upHue,upSat,upVal)\n",
    "    \n",
    "    return np.array([upHue,upSat,upVal], dtype=np.uint8), np.array([lowerHue,lowerSat,lowerVal], dtype=np.uint8) #Upper then Lowers\n",
    "\n",
    "def queue_ave(q):\n",
    "    rebuilt_queue_list = []\n",
    "    class_representations = np.zeros(20)\n",
    "    qSize = q.qsize()\n",
    "    while not q.empty():\n",
    "        prediction = q.get()\n",
    "        # Rebuild q\n",
    "        # rebuilt_queue_list.append(prediction) # Enabled if there should not be a 1second sample time (immediate, no buffering)\n",
    "        \n",
    "        #get confidence from tuple\n",
    "        confidence = prediction[1]\n",
    "        #Adds the current highest confidence in class predictions to each class(row of the array)\n",
    "        class_representations[prediction[0]] = class_representations[prediction[0]] + confidence\n",
    "        \n",
    "    #find highest prediction sum\n",
    "    avgConfidence = np.amax(class_representations) / qSize\n",
    "    # return the class with the highest confidence averaged over all predictions over some num frames, avg confidence \n",
    "    # print(np.argmax(class_representations), avgConfidence)\n",
    "    return np.argmax(class_representations), avgConfidence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8139a6a-b58b-4ad4-90cc-4bfd7f525b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock 1.0\n",
      "paper 0.9310344704266252\n"
     ]
    }
   ],
   "source": [
    "### Pose Estimation based on data Feed and skin tone values.\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "currentPrediciton = 'Estimation:'\n",
    "# Initializing a queue\n",
    "\n",
    "q = Queue(maxsize = qMaxSize)\n",
    "\n",
    "cap = cv2.VideoCapture(2)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "            continue\n",
    "            \n",
    "    frame=cv2.flip(frame,1)#flip on vertical\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "    #define region of interest\n",
    "    roi = frame[350:545, 350:690] #240 x 195 : 65 x 80\n",
    "    #add rectangle around region of interest\n",
    "    cv2.rectangle(frame,(350,350),(590,545),(0,255,0),0)    \n",
    "    \n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV) \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define default skin tones H S V\n",
    "    lower_skin = np.array([0, 10, 60], dtype=np.uint8) # 0, 20, 70    89, 47, 42     0, 10, 60\n",
    "    upper_skin = np.array([20, 150, 255], dtype=np.uint8) # 20, 255, 255     236, 188, 180      20, 150, 255\n",
    "    \n",
    "    # Create default mask\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    # Define custom skin tones H S V \n",
    "    #Skin Tone from Face\n",
    "    averageColorRBG = (126, 80, 65)# RGB  (20, 44, 108)\n",
    "    \n",
    "    ##Simoultaneous FTST, not recommended. Calibrate using the method FTST instead.\n",
    "    if simoultFTST:\n",
    "        avgColor = (126, 80, 65)\n",
    "        ##Face recognition to identify skin color\n",
    "        #import OpenCV face detection model\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "        #custom width control\n",
    "        custom_width = custom_width_g\n",
    "\n",
    "        # Convert into grayscale\n",
    "        grayScaleFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(grayScaleFrame, 1.1, 4)\n",
    "\n",
    "            # Draw rectangle around the faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.rectangle(frame, (x+custom_width, y), (x+w-custom_width, y+h), (0, 255, 0), 1)\n",
    "            try:\n",
    "                sobel = sobelFilter(grayScaleFrame)\n",
    "                cv2.imshow('Sobel Approx', sobel)\n",
    "            except:\n",
    "                pass\n",
    "            #Slice command given\n",
    "        if keyboard.is_pressed('s'):  # if key 'q' is pressed \n",
    "            # Detect faces\n",
    "            faces = face_cascade.detectMultiScale(grayScaleFrame, 1.1, 4)\n",
    "            # Draw rectangle around the faces\n",
    "            for (x, y, w, h) in faces:\n",
    "                #sliced frame\n",
    "                try:\n",
    "                    slicedSegment = frame[y:y+h,x+custom_width:x+w-custom_width]\n",
    "                    img_temp = slicedSegment.copy()\n",
    "                     #find avg pixel value for each face\n",
    "                    img_temp[:,:,0], img_temp[:,:,1], img_temp[:,:,2] = np.average(slicedSegment, axis=(0,1))\n",
    "                    avgColor = (int(img_temp[0][0][0]), int(img_temp[0][0][1]), int(img_temp[0][0][2]))\n",
    "                    cv2.rectangle(frame, (x+custom_width, y), (x+w-custom_width, y+h), avgColor, -1)\n",
    "                except:\n",
    "                    print('err')\n",
    "            averageColorRBG = avgColor\n",
    "    ##End of simulFTST\n",
    "        \n",
    "    \n",
    "    \n",
    "    # customColorRGB = (116, 88, 83)\n",
    "    #Default range\n",
    "    hueThresh = 5 #Light Temperature variance, Multiple lightsources with different warmths - higher\n",
    "    satThresh = 70 #Lighter skin requires higher saturation threshholds\n",
    "    valThresh = 95 #Lighting variance of enviornment\n",
    "    custom_upper_skin, custom_lower_skin = customSkinTones(averageColorRBG, hueThresh, satThresh, valThresh)\n",
    "    \n",
    "    custom_mask = cv2.inRange(hsv, custom_lower_skin, custom_upper_skin)\n",
    "   \n",
    "    ##Improve the mask\n",
    "    #extrapolate the hand to fill dark spots within\n",
    "    mask = cv2.dilate(mask,kernel,iterations = 4)\n",
    "    #blur to reduce noise\n",
    "    mask = cv2.GaussianBlur(mask,(5,5),100) \n",
    "    # custom_mask = cv2.dilate(custom_mask,kernel,iterations = 2)\n",
    "    custom_mask = cv2.GaussianBlur(custom_mask,(5,5),100) \n",
    "    \n",
    "    freshOutput = np.zeros((195,240,3), np.uint8)\n",
    "    \n",
    "    try:\n",
    "        #find contours\n",
    "        # contours,hierarchy= cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        custom_contours,custom_hierarchy= cv2.findContours(custom_mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # find max area contour\n",
    "        if custom_contours:\n",
    "            cnt = max(custom_contours, key = lambda x: cv2.contourArea(x)) #if contours were found identify max inner area cnt \n",
    "            # cv2.drawContours(frame, cnt, -1, color=(255, 255, 255), thickness=cv2.FILLED)\n",
    "            \n",
    "            # approx the contour\n",
    "            epsilon = 0.0005*cv2.arcLength(cnt,True)\n",
    "            approx= cv2.approxPolyDP(cnt,epsilon,True)\n",
    "            # cv2.drawContours(custom_mask, cnt, -1, (0, 255, 0), 3)\n",
    "            # Optimal Output\n",
    "            cv2.fillPoly(freshOutput, pts = [approx], color = (240, 240, 240))\n",
    "            # cv2.fillPoly(custom_mask, pts = [approx], color = (240, 240, 240))\n",
    "            freshOutput = cv2.GaussianBlur(freshOutput,(5,5),100) \n",
    "            freshOutput = cv2.erode(freshOutput,kernel,iterations = 4)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ## Resize mask\n",
    "    resizedMask = cv2.resize(freshOutput,(80,65), interpolation = cv2.INTER_AREA)\n",
    "    # convert from Mat to numpy array\n",
    "    np_image_data = np.asarray(resizedMask)\n",
    "    np_final = np.expand_dims(np_image_data,axis = 0)\n",
    "    #adds the None(on axis 0) dimensions that the model is expecting\n",
    "    images = np.vstack([np_final])\n",
    "    #adds the three channels of \"color\" (on axis 3) that the model is expecting\n",
    "    \n",
    "    try:\n",
    "        # print(images.shape)\n",
    "        #Predict\n",
    "        prediction = model.predict(images)\n",
    "        highestConfidence = np.amax(prediction)\n",
    "        classOfHighest = poses[np.argmax(prediction)]\n",
    "        # Adding to Confidence Queue\n",
    "        q.put((np.argmax(prediction),np.amax(prediction))) #Adds the class index and confidence of the prediciton as a tuple to the q\n",
    "        if not q.qsize() < qMaxSize:\n",
    "            q.get()\n",
    "            #Print\n",
    "            result = queue_ave(q)\n",
    "            if result[1] > confidenceThreshold:\n",
    "                print(poses[result[0]],result[1])\n",
    "                currentPrediciton = 'Estimation: ' + str(poses[result[0]]) + ' : ' + str(round(result[1], 4))\n",
    "            else:\n",
    "                currentPrediciton = 'Estimation: sampling...'\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cv2.putText(frame,currentPrediciton,(300,300), font, 1,(255,255,255),2, cv2.LINE_4)\n",
    "    \n",
    "    #show video feed\n",
    "    cv2.imshow('Raw Video Input',frame)\n",
    "    \n",
    "    #Show defaul mask\n",
    "    cv2.imshow('Default Skin Mask', mask)\n",
    "    #Show mask\n",
    "    cv2.imshow('Custom Skin Mask',custom_mask)\n",
    "    #Show clean output\n",
    "    cv2.imshow('Optimized',freshOutput)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd60f84-8c2d-4e5d-a124-78563071279c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def faceToSkinTone():\n",
    "    avgColor = (126, 80, 65)\n",
    "    ##Face recognition to identify skin color\n",
    "    #import OpenCV face detection model\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    #custom width control\n",
    "    custom_width = custom_width_g\n",
    "\n",
    "    #Webcam Capture Skeleton\n",
    "    cap = cv2.VideoCapture(2) \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Convert into grayscale\n",
    "        grayScaleFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(grayScaleFrame, 1.1, 4)\n",
    "        \n",
    "        # Draw rectangle around the faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.rectangle(frame, (x+custom_width, y), (x+w-custom_width, y+h), (0, 255, 0), 1)\n",
    "            try:\n",
    "                sobel = sobelFilter(grayScaleFrame)\n",
    "                cv2.imshow('Sobel Approx', sobel)\n",
    "            except:\n",
    "                pass\n",
    "        #Slice command given\n",
    "        if keyboard.is_pressed('s'):  # if key 'q' is pressed \n",
    "            # Detect faces\n",
    "            faces = face_cascade.detectMultiScale(grayScaleFrame, 1.1, 4)\n",
    "            # Draw rectangle around the faces\n",
    "            for (x, y, w, h) in faces:\n",
    "                # cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                #sliced frame\n",
    "                slicedSegment = frame[y:y+h,x+custom_width:x+w-custom_width]\n",
    "                img_temp = slicedSegment.copy()\n",
    "                 #find avg pixel value for each face\n",
    "                img_temp[:,:,0], img_temp[:,:,1], img_temp[:,:,2] = np.average(slicedSegment, axis=(0,1))\n",
    "                avgColor = (int(img_temp[0][0][0]), int(img_temp[0][0][1]), int(img_temp[0][0][2]))\n",
    "                print(avgColor)\n",
    "                try:\n",
    "                    cv2.rectangle(frame, (x+custom_width, y), (x+w-custom_width, y+h), avgColor, -1)\n",
    "                except:\n",
    "                    print('oopsies')\n",
    "\n",
    "        cv2.imshow('Skin Color Calibration', frame)\n",
    "        \n",
    "        # cv2.imshow('BW Channel', grayScaleFrame)     \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return avgColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69abb0b0-d3d6-4a63-9805-84eb18663a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#alternate Sobel Filtering to better define contours, face ROI\n",
    "def sobelFilter(frame):\n",
    "    # Calculation of Sobelx\n",
    "    sobelx = cv2.Sobel(frame,cv2.CV_64F,1,0,ksize=5)\n",
    "\n",
    "    # Calculation of Sobely\n",
    "    sobely = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "    weightedFilterCombination = cv2.addWeighted(sobelx, 0.4, sobely, 0.3, 0)\n",
    "    return weightedFilterCombination\n",
    "# # Calculation of Laplacian\n",
    "# laplacian = cv2.Laplacian(frame,cv2.CV_64F)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02480421-3dae-41d5-9c63-be3bcd2081b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Helpful for startup\n",
    "# Grab indices of all Video Capture Devices (Webcams, virtual cams, ect.)\n",
    "index = 0\n",
    "arr = []\n",
    "while True:\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    if not cap.read()[0]:\n",
    "        break\n",
    "    else:\n",
    "        arr.append(index)\n",
    "    cap.release()\n",
    "    index += 1\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9a91be2-c56c-4277-a871-25576f09d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 68, 77)\n",
      "(70, 70, 87)\n",
      "(83, 86, 109)\n",
      "(83, 90, 117)\n",
      "(84, 91, 118)\n",
      "(83, 89, 116)\n",
      "(83, 89, 116)\n"
     ]
    }
   ],
   "source": [
    "#Run stand alone instance to calibrate skin color\n",
    "print(faceToSkinTone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260fd9d-18c8-438d-a53d-eff03e5d5dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
